{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#global variables\n",
    "width = 0\n",
    "height = 0\n",
    "entranceCounter = 0\n",
    "exitCounter = 0\n",
    "minContourArea = 600  #Adjust ths value according to tweak the size of the moving object found\n",
    "binarizationThreshold = 30  #Adjust ths value to tweak the binarization\n",
    "offsetEntranceLine = 30  #offset of the entrace line above the center of the image\n",
    "offsetExitLine = 60 #offset of the entrance line below the center of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if an object in entering in monitored zone\n",
    "def checkEntranceLineCrossing(y, coorYEntranceLine, coorYExitLine):\n",
    "    absDistance = abs(y - coorYEntranceLine)\n",
    "\n",
    "    if ((absDistance <= 2) and (y < coorYExitLine)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if an object in exitting from monitored zone\n",
    "def checkExitLineCrossing(y, CoorYEntranceLine, CoorYExitLine):\n",
    "    AbsDistance = abs(y - CoorYExitLine)\t\n",
    "\n",
    "    if ((AbsDistance <= 2) and (y > CoorYEntranceLine)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greyScaleConversion(frame):\n",
    "    \"\"\"\n",
    "    Convert the image from 3 channels to greyscale to reduce the compute required to run it.\n",
    "    \"\"\"\n",
    "    return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianBlurring(frame):\n",
    "    \"\"\"\n",
    "    Preprocess the image by applying a gaussian blur\n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(frame, ksize =(21, 21), sigmaX = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageDiff(referenceFrame, frame):\n",
    "    \"\"\"\n",
    "    Get the difference between 2 frames to isolate and retrieve only the moving object\n",
    "    \"\"\"\n",
    "    return cv2.absdiff(referenceFrame, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholdImage(frame, binarizationThreshold=70):\n",
    "    \"\"\"\n",
    "    Threshold the image to make it black and white. values above binarizationThreshold are made white and the rest\n",
    "    is black\n",
    "    \"\"\"\n",
    "    return cv2.threshold(frame, binarizationThreshold, 255, cv2.THRESH_BINARY)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilateImage(frame, interations=2 ):\n",
    "    \"\"\"\n",
    "    Dilate the image to prevent spots that are black inside an image from being counted as individual objects\n",
    "    \"\"\"\n",
    "    return cv2.dilate(frame, None, iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(frame):\n",
    "    \"\"\"\n",
    "    Get the contours in the frame \n",
    "    @return: contours\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContourBound(contour):\n",
    "    \"\"\"\n",
    "    Returns a rectangle that is a bound around the contour.\n",
    "    @return: contour Bounds\n",
    "    \"\"\"\n",
    "    (x,y,w,h) = cv2.boundingRect(contour)\n",
    "    return (x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContourCentroid(x, y, w, h):\n",
    "    \"\"\"\n",
    "    Get the centroid/center of the countours you have\n",
    "    @return: The coordinates of the  center points\n",
    "    \"\"\"\n",
    "    coordXCentroid = (x+x+w)/2\n",
    "    coordYCentroid = (y+y+h)/2\n",
    "    objectCentroid = (int(coordXCentroid),int(coordYCentroid))\n",
    "    return objectCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(\"Road traffic video for object recognition.mp4\")\n",
    "\n",
    "#force 640x480 webcam resolution\n",
    "camera.set(3,640)\n",
    "camera.set(4,480)\n",
    "\n",
    "referenceFrame = None\n",
    "\n",
    "#The webcam maybe get some time / captured frames to adapt to ambience lighting. For this reason, \n",
    "#some frames are grabbed and discarted.\n",
    "for i in range(0,20):\n",
    "    (grabbed, Frame) = camera.read()\n",
    "\n",
    "while True:    \n",
    "    (grabbed, Frame) = camera.read()\n",
    "    height = np.size(Frame,0)\n",
    "    width = np.size(Frame,1)\n",
    "\n",
    "    #if cannot grab a frame, this program ends here.\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    #gray-scale convertion and Gaussian blur filter applying\n",
    "    grayFrame = greyScaleConversion(Frame)\n",
    "    blurredFrame = gaussianBlurring(grayFrame)\n",
    "    \n",
    "    if referenceFrame is None:\n",
    "        referenceFrame = blurredFrame\n",
    "        continue\n",
    "\n",
    "    #Background subtraction and image binarization\n",
    "    frameDelta = getImageDiff(referenceFrame, blurredFrame)\n",
    "    frameThresh = thresholdImage(frameDelta, binarizationThreshold)\n",
    "    \n",
    "    #Dilate image and find all the contours\n",
    "    dilatedFrame = dilateImage(frameThresh)\n",
    "    cnts = getContours(dilatedFrame)\n",
    "\n",
    "    qttyOfContours = 0\n",
    "\n",
    "    #plot reference lines (entrance and exit lines) \n",
    "    coordYEntranceLine = int((height / 2)-offsetEntranceLine)\n",
    "    coordYExitLine = int((height / 2)+offsetExitLine)\n",
    "    cv2.line(Frame, (0,coordYEntranceLine), (width,coordYEntranceLine), (255, 0, 0), 2)\n",
    "    cv2.line(Frame, (0,coordYExitLine), (width,coordYExitLine), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "    #check all found contours\n",
    "    for c in cnts:\n",
    "        #if a contour has small area, it'll be ignored\n",
    "        if cv2.contourArea(c) < minContourArea:\n",
    "            continue\n",
    "\n",
    "        qttyOfContours = qttyOfContours+1    \n",
    "\n",
    "        #draw an rectangle \"around\" the object\n",
    "        (x, y, w, h) = getContourBound(c)\n",
    "        cv2.rectangle(Frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        #find object's centroid\n",
    "        objectCentroid = getContourCentroid(x, y, w, h)\n",
    "        cv2.circle(Frame, objectCentroid, 1, (0, 0, 0), 5)\n",
    "        \n",
    "        coordXCentroid = (x+x+w)/2\n",
    "        coordYCentroid = (y+y+h)/2\n",
    "        \n",
    "        if (checkEntranceLineCrossing(coordYCentroid,coordYEntranceLine,coordYExitLine)):\n",
    "            entranceCounter += 1\n",
    "\n",
    "        if (checkExitLineCrossing(coordYCentroid,coordYEntranceLine,coordYExitLine)):  \n",
    "            exitCounter += 1\n",
    "\n",
    "    #print(\"Total countours found: \" +str(QttyOfContours))\n",
    "\n",
    "    #Write entrance and exit counter values on frame and shows it\n",
    "    cv2.putText(Frame, \"Entrances: {}\".format(str(entranceCounter)), (10, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (250, 0, 1), 2)\n",
    "    cv2.putText(Frame, \"Exits: {}\".format(str(exitCounter)), (10, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Original Frame\", Frame)\n",
    "    cv2.waitKey(1);\n",
    "\n",
    "\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
