{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "from random import randint\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a method to use to create the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "\n",
    "def createTrackerByName(trackerType):\n",
    "  # Create a tracker based on tracker name\n",
    "  if trackerType.upper() == trackerTypes[0]:\n",
    "    tracker = cv2.TrackerBoosting_create()\n",
    "  elif trackerType.upper() == trackerTypes[1]: \n",
    "    tracker = cv2.TrackerMIL_create()\n",
    "  elif trackerType.upper() == trackerTypes[2]:\n",
    "    tracker = cv2.TrackerKCF_create()\n",
    "  elif trackerType.upper() == trackerTypes[3]:\n",
    "    tracker = cv2.TrackerTLD_create()\n",
    "  elif trackerType.upper() == trackerTypes[4]:\n",
    "    tracker = cv2.TrackerMedianFlow_create()\n",
    "  elif trackerType.upper() == trackerTypes[5]:\n",
    "    print(\"Ensure you have the goturn caffemodel in your directory. To download it, see reference 4\")\n",
    "    tracker = cv2.TrackerGOTURN_create()\n",
    "  elif trackerType.upper() == trackerTypes[6]:\n",
    "    tracker = cv2.TrackerMOSSE_create()\n",
    "  elif trackerType.upper() == trackerTypes[7]:\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "  else:\n",
    "    tracker = None\n",
    "    print('Incorrect tracker name')\n",
    "    print('Available trackers are:')\n",
    "    for t in trackerTypes:\n",
    "      print(t)\n",
    "     \n",
    "  return tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Attempt to read the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set video0 to a video with ~4 minutes of content.\n",
    "#Set video1 to a car chase\n",
    "video0 = \"ball rebounding and bouncing all around the screen with trails and music 1080p HD Animation.mp4\"\n",
    "video1 = \"1-Stolen Dodge Hellcat Outruns Chopper in Houston Police Chase! Driver Almost Makes it.mp4\"\n",
    "video = video1\n",
    "capture = cv2.VideoCapture(video)\n",
    "\n",
    "#Attempt to read a frame\n",
    "success, frame = capture.read()\n",
    "if not success:\n",
    "    print(\"Video doesn't exist.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw bounding boxes around the object to be tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundBoxes = []\n",
    "# color is going to be initialized to a random color for every object\n",
    "colors = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected bounding boxes[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# A loop to run the object selection till \"q\" is pressed\n",
    "while not True:\n",
    "    boundbox = cv2.selectROI('tracker', frame)\n",
    "    boundBoxes.append(boundbox)\n",
    "    colors.append((randint(0,255), randint(0, 255), randint(0, 255)))\n",
    "    print(\"Press q/ESC to quit selecting boxes and start tracking\")\n",
    "    print(\"Press Space to set the next object to select\")\n",
    "    k = cv2.waitKey(0)\n",
    "    if (k == 113 or k==27):\n",
    "        break        \n",
    "        \n",
    "cv2.destroyWindow(\"tracker\")\n",
    "print(\"Selected bounding boxes{}\".format(boundBoxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set bounding box and color to a fixed location so test is reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the bounding box for the videos so you can reproduce the video\n",
    "if video==video0:\n",
    "    boundBoxes = [(0, 0, 11, 16)]\n",
    "    colors = [(44, 156, 222)]\n",
    "if video ==video1:\n",
    "    boundBoxes = [(258, 156, 76, 32)]\n",
    "    colors = [(44, 156, 222)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a Multi-tracker to track the boundingBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensure you have the goturn caffemodel in your directory. To download it, see reference 4\n"
     ]
    }
   ],
   "source": [
    "#Select a tracker from the trackerTypes\n",
    "trackerTypes = ['BOOSTING', 'MIL', 'KCF','TLD', 'MEDIANFLOW', 'GOTURN', 'MOSSE', 'CSRT']\n",
    "#Enter the name of the tracker or index it \n",
    "trackerType = \"GOTURN\"\n",
    "\n",
    "#Create the multitracker object\n",
    "multiTracker = cv2.MultiTracker_create()\n",
    "\n",
    "#initialize the multitracker\n",
    "for boundbox in boundBoxes:\n",
    "    multiTracker.add(createTrackerByName(trackerType), frame, boundbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the VideoWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the frame dimensions\n",
    "frame_width = int(capture.get(3))\n",
    "frame_height = int(capture.get(4))\n",
    "\n",
    "out = cv2.VideoWriter(trackerType+\".avi\",cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "## text that shows the frames per second\n",
    "originalFPS = round(capture.get(cv2.CAP_PROP_FPS), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the video and begin object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tracking(capture, multiTracker, trackerType):\n",
    "    start = time.time()\n",
    "    frameCount = 1\n",
    "    #Process video and track objects. I use 1695 to make the algorithms compare the same frames in the video.\n",
    "    while capture.isOpened() and frameCount < 1695:\n",
    "        frameCount+=1\n",
    "        runningTime = time.time()\n",
    "        success, frame = capture.read()\n",
    "        if not success:\n",
    "            break\n",
    "        #get updated location of objects being tracked in subsequent fram\n",
    "        success, boxes = multiTracker.update(frame)\n",
    "        elapsedSeconds = time.time() - start\n",
    "        #Draw box around tracked objects\n",
    "        p1  = []\n",
    "        p2 = []\n",
    "        for i, newbox in enumerate(boxes):\n",
    "            p1 = (int(newbox[0]), int(newbox[1]))\n",
    "            p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))\n",
    "            \n",
    "\n",
    "        #Show the frame and insert appropriate text into the frame\n",
    "        cv2.putText(frame, trackerType, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA )\n",
    "        if success:\n",
    "            avgTrackingFPS = \"Average Tracking FPS: \" + str(round(frameCount/elapsedSeconds+0.000000001, 3))\n",
    "            runTrackingFPS = \"Current Tracking FPS: \" + str(round(1/(time.time()-runningTime+0.000000001), 3))\n",
    "            oFPS = \"Input FPS: \" + str(originalFPS)\n",
    "            cv2.putText(frame, avgTrackingFPS, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA )\n",
    "            cv2.putText(frame, runTrackingFPS, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA )\n",
    "            cv2.putText(frame, oFPS, (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA )\n",
    "            cv2.rectangle(frame, p1, p2, colors[i], 2, 1)\n",
    "        else:\n",
    "            failText = \"Tracking Failure\"\n",
    "            cv2.putText(frame, failText, (180, 240), cv2.FONT_HERSHEY_COMPLEX, 1.0, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.imshow(trackerType, frame)\n",
    "        out.write(frame)\n",
    "        #Quit if the Escape button is pressed\n",
    "        if cv2.waitKey(1) & 0xFF ==27:\n",
    "            out.release()\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    print(frameCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4:Insufficient memory) Failed to allocate 36422871600 bytes in function 'cv::OutOfMemoryError'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-32cd7451e201>\u001b[0m in \u001b[0;36mrun_tracking\u001b[1;34m(capture, multiTracker, trackerType)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m#get updated location of objects being tracked in subsequent fram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiTracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0melapsedSeconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#Draw box around tracked objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.0) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\alloc.cpp:55: error: (-4:Insufficient memory) Failed to allocate 36422871600 bytes in function 'cv::OutOfMemoryError'\n"
     ]
    }
   ],
   "source": [
    "%time run_tracking(capture, multiTracker, trackerType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(success)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://www.learnopencv.com/multitracker-multiple-object-tracking-using-opencv-c-python/\n",
    "2. Opencv docs\n",
    "3. https://www.learnopencv.com/goturn-deep-learning-based-object-tracking/\n",
    "4. https://www.dropbox.com/sh/77frbrkmf9ojfm6/AACgY7-wSfj-LIyYcOgUSZ0Ua?dl=0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
